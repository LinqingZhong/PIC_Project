from rag_retriever import RAGRetriever
from rag_retriever_bert import RAGRetrieverBERT  
from schema_retriever import retrieve_schema
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

def is_chinese(text):
    zh_count = sum('\u4e00' <= ch <= '\u9fff' for ch in text)
    ratio = zh_count / max(len(text), 1)
    return ratio > 0.3  

def detect_lang(text):
    return "zh" if is_chinese(text) else "en"

# model_name = "Qwen/Qwen-7B-Chat"
# tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
# model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True).half().cuda()
# model.eval()

retriever_zh = RAGRetrieverBERT(db_path="resources/faiss_index_cn")
retriever_en = RAGRetriever(db_path="resources/faiss_index_en")
retriever_zh.load()
retriever_en.load()


def get_rag_context(question):
    lang = detect_lang(question)
    print(f"Detected language: {lang}")
    if lang == "zh-cn" or lang == "zh":
        docs = retriever_zh.retrieve(question)
        return "\n".join(docs), lang
    else:
        docs = retriever_en.retrieve(question)
        return "\n".join(docs), lang

def rag_generate(question, schema=""):
    context, lang = get_rag_context(question)
    schema = retrieve_schema(question, lang=lang)
    prompt = f"""You are an expert in knowledge graph and question answering.

Graph Schema:
{schema}

Reference Documents:
{context}

Question: {question}

Answer (Cypher):
"""
    return prompt
    # inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    # with torch.no_grad():
    #     outputs = model.generate(
    #         **inputs,
    #         max_new_tokens=256,
    #         do_sample=True,
    #         temperature=0.7,
    #         top_p=0.9
    #     )

    # response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    # return response[len(prompt):].strip()


question_zh = "ä»€ä¹ˆæ˜¯åœ°çƒ­èƒ½ï¼Ÿ"
question_en = "How to process crude oil ?"

print("ğŸŒ ä¸­æ–‡é—®é¢˜ï¼š", question_zh)
print("ğŸ¤– Cypher:\n", rag_generate(question_zh))

print("\nğŸŒ English question:", question_en)
print("ğŸ¤– Cypher:\n", rag_generate(question_en))
